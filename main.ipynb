{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements in df_cases: 87\n",
      "Elements in df_deaths: 87\n",
      "Elements in df_recovered: 87\n",
      "              date  date_n  Afghanistan  Albania  Algeria  Andorra  Angola  \\\n",
      "date_n                                                                       \n",
      "21      2020-01-22      21          0.0      0.0      0.0      0.0     0.0   \n",
      "22      2020-01-23      22          0.0      0.0      0.0      0.0     0.0   \n",
      "23      2020-01-24      23          0.0      0.0      0.0      0.0     0.0   \n",
      "24      2020-01-25      24          0.0      0.0      0.0      0.0     0.0   \n",
      "25      2020-01-26      25          0.0      0.0      0.0      0.0     0.0   \n",
      "...            ...     ...          ...      ...      ...      ...     ...   \n",
      "103     2020-04-13     103        665.0    467.0   1983.0    646.0    19.0   \n",
      "104     2020-04-14     104        714.0    475.0   2070.0    659.0    19.0   \n",
      "105     2020-04-15     105        784.0    494.0   2160.0    673.0    19.0   \n",
      "106     2020-04-16     106        840.0    518.0   2268.0    673.0    19.0   \n",
      "107     2020-04-17     107        906.0    539.0   2418.0    696.0    19.0   \n",
      "\n",
      "        Antigua and Barbuda  Argentina  Armenia  ...  Yemen  Zambia  Zimbabwe  \\\n",
      "date_n                                           ...                            \n",
      "21                      0.0        0.0      0.0  ...    0.0     0.0       0.0   \n",
      "22                      0.0        0.0      0.0  ...    0.0     0.0       0.0   \n",
      "23                      0.0        0.0      0.0  ...    0.0     0.0       0.0   \n",
      "24                      0.0        0.0      0.0  ...    0.0     0.0       0.0   \n",
      "25                      0.0        0.0      0.0  ...    0.0     0.0       0.0   \n",
      "...                     ...        ...      ...  ...    ...     ...       ...   \n",
      "103                    23.0     2208.0   1039.0  ...    1.0    45.0      17.0   \n",
      "104                    23.0     2277.0   1067.0  ...    1.0    45.0      17.0   \n",
      "105                    23.0     2443.0   1111.0  ...    1.0    48.0      23.0   \n",
      "106                    23.0     2571.0   1159.0  ...    1.0    48.0      23.0   \n",
      "107                    23.0     2669.0   1201.0  ...    1.0    52.0      24.0   \n",
      "\n",
      "          Italia  EmiliaRomagna  Lombardia   Veneto   Parma  Reggio  Modena  \n",
      "date_n                                                                       \n",
      "21           NaN            NaN        NaN      NaN     NaN     NaN     NaN  \n",
      "22           NaN            NaN        NaN      NaN     NaN     NaN     NaN  \n",
      "23           NaN            NaN        NaN      NaN     NaN     NaN     NaN  \n",
      "24           NaN            NaN        NaN      NaN     NaN     NaN     NaN  \n",
      "25           NaN            NaN        NaN      NaN     NaN     NaN     NaN  \n",
      "...          ...            ...        ...      ...     ...     ...     ...  \n",
      "103     159516.0        20440.0    60314.0  14251.0  2573.0  3888.0  3132.0  \n",
      "104     162488.0        20752.0    61326.0  14432.0  2582.0  3947.0  3180.0  \n",
      "105     165155.0        21029.0    62153.0  14624.0  2616.0  3982.0  3217.0  \n",
      "106     168941.0        21486.0    63094.0  14990.0  2698.0  4053.0  3262.0  \n",
      "107     172434.0        21834.0    64135.0  15374.0  2725.0  4090.0  3301.0  \n",
      "\n",
      "[87 rows x 194 columns]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Spyder Editor\n",
    "\n",
    "This is a temporary script file.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import fsolve\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "#import matplotlib\n",
    "#%matplotlib inline\n",
    "from itertools import compress\n",
    "import traceback\n",
    "from scipy.signal import lfilter, filtfilt\n",
    "#colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "import altair as alt\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Caricamento base dati\n",
    "\"\"\"\n",
    "def load(keys):\n",
    "    def extract_ita(tipo, code):\n",
    "        if tipo == \"nat\":\n",
    "            url = \"C:\\git_covid19\\italia\\COVID-19\\dati-andamento-nazionale\\dpc-covid19-ita-andamento-nazionale.csv\"\n",
    "            df = pd.read_csv(url)\n",
    "        elif tipo == \"reg\":\n",
    "            url = \"C:\\git_covid19\\italia\\COVID-19\\dati-regioni\\dpc-covid19-ita-regioni.csv\"\n",
    "            df_raw = pd.read_csv(url)\n",
    "            is_code =  df_raw['codice_regione']==code\n",
    "            df = df_raw[is_code]\n",
    "        elif tipo == \"prov\":\n",
    "            url = \"C:\\git_covid19\\italia\\COVID-19\\dati-province\\dpc-covid19-ita-province.csv\"\n",
    "            df_raw = pd.read_csv(url)\n",
    "            is_code =  df_raw['codice_provincia']==code\n",
    "            df = df_raw[is_code]\n",
    "    \n",
    "        # Interpretazione\n",
    "        #print(df)\n",
    "        try:\n",
    "            df = df[['data', 'totale_casi', 'deceduti','dimessi_guariti']].copy()\n",
    "        except:\n",
    "            df = df[['data', 'totale_casi']].copy()\n",
    "            df['deceduti'] = 0\n",
    "            df['dimessi_guariti'] = 0\n",
    "            \n",
    "        #df = df.loc[:,['data','totale_casi','deceduti','dimessi_guariti']]\n",
    "        date = df['data']\n",
    "        FMT = '%Y-%m-%dT%H:%M:%S'\n",
    "        df['date_n'] = pd.Series(date.map(lambda x : (datetime.strptime(x, FMT) - datetime.strptime(\"2020-01-01T00:00:00\", FMT)).days  ), index=df.index)\n",
    "        df.index = df['date_n']\n",
    "    \n",
    "        return df\n",
    "    \n",
    "    def extract_jhu(url):\n",
    "        df = pd.read_csv(url, delimiter=',')\n",
    "        df = df.transpose()\n",
    "        \n",
    "        # Create date_n\n",
    "        date_n = list(df.index[4:].values)\n",
    "        try:\n",
    "            FMT = '%m/%d/%y'\n",
    "            date_n = map(lambda x : (datetime.strptime(x, FMT) - datetime.strptime(\"01/01/20\", FMT)).days, date_n)\n",
    "        except:\n",
    "            FMT = '%m/%d/%Y'\n",
    "            date_n = map(lambda x : (datetime.strptime(x, FMT) - datetime.strptime(\"01/01/2020\", FMT)).days, date_n)\n",
    "        new_header = df.iloc[1]\n",
    "        df.columns = new_header\n",
    "        df = df[4:]\n",
    "        df['date_n'] = pd.Series(date_n, index=df.index)\n",
    "        \n",
    "        # Format date with a standard format\n",
    "        df['date'] = pd.Series(df.index, index=df.index)\n",
    "        FMTout = \"%Y-%m-%d\"\n",
    "        try:\n",
    "            FMTin = \"%m/%d/%y\"\n",
    "            #df['date'] = map(lambda x : (datetime.strftime(datetime.strptime(x, FMTin), FMTout)), pd.Series(df.index, index=df.index))\n",
    "            df['date'] = list(datetime.strftime(datetime.strptime(x, FMTin), FMTout) for x in pd.Series(df.index, index=df.index))\n",
    "        except:\n",
    "            FMTin = \"%m/%d/%Y\"\n",
    "            #df['date'] = map(lambda x : (datetime.strftime(datetime.strptime(x, FMTin), FMTout)), pd.Series(df.index, index=df.index))\n",
    "            df['date'] = list(datetime.strftime(datetime.strptime(x, FMTin), FMTout) for x in pd.Series(df.index, index=df.index))\n",
    "        \n",
    "        # Index based on date_n        \n",
    "        #df.index = range(len(df))\n",
    "        df.index = df['date_n']\n",
    "        \n",
    "        # Sum country regions\n",
    "        df = df.groupby(level=0, axis=1).sum()\n",
    "        \n",
    "        # Reorder columns to make in more readable\n",
    "        cols = df.columns.tolist()\n",
    "        cols = cols[-2:] + cols[:-2]\n",
    "        df = df[cols]\n",
    "        \n",
    "        # Filter only countris I am interested in\n",
    "        #df = df[['date_n','Italy', 'Germany', 'Spain', 'United Kingdom', 'France', 'Austria', 'US', 'China']]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def concatandrename(df, df2, column, name):\n",
    "        df = pd.concat([df, df2[column]], axis=1)\n",
    "        df = df.rename(columns={column: name})\n",
    "        return df\n",
    "        \n",
    "    # Extract from JHU database\n",
    "    url_jhu_cases = \"C:\\git_covid19\\jhu\\COVID-19\\csse_covid_19_data\\csse_covid_19_time_series\\\\time_series_covid19_confirmed_global.csv\"\n",
    "    url_jhu_deaths = \"C:\\git_covid19\\jhu\\COVID-19\\csse_covid_19_data\\csse_covid_19_time_series\\\\time_series_covid19_deaths_global.csv\"\n",
    "    url_jhu_recovered = \"C:\\git_covid19\\jhu\\COVID-19\\csse_covid_19_data\\csse_covid_19_time_series\\\\time_series_covid19_recovered_global.csv\"\n",
    "    df_cases = extract_jhu(url_jhu_cases)\n",
    "    df_deaths = extract_jhu(url_jhu_deaths)\n",
    "    df_recovered = extract_jhu(url_jhu_recovered)\n",
    "    \n",
    "    # Extract from Ita database\n",
    "    df_ita = extract_ita(\"nat\", -1)\n",
    "    df_emiliaromagna = extract_ita(\"reg\", 8)\n",
    "    df_lombardia = extract_ita(\"reg\", 3)\n",
    "    df_veneto = extract_ita(\"reg\", 5)\n",
    "    df_parma = extract_ita(\"prov\", 34)\n",
    "    df_reggioemilia = extract_ita(\"prov\", 35)\n",
    "    df_modena = extract_ita(\"prov\", 36)\n",
    "    \n",
    "    # Merge Ita data with JHU data\n",
    "    df_cases = concatandrename(df_cases, df_ita, \"totale_casi\", \"Italia\")\n",
    "    df_cases = concatandrename(df_cases, df_emiliaromagna, \"totale_casi\", \"EmiliaRomagna\")\n",
    "    df_cases = concatandrename(df_cases, df_lombardia, \"totale_casi\", \"Lombardia\")\n",
    "    df_cases = concatandrename(df_cases, df_veneto, \"totale_casi\", \"Veneto\")\n",
    "    df_cases = concatandrename(df_cases, df_parma, \"totale_casi\", \"Parma\")\n",
    "    df_cases = concatandrename(df_cases, df_reggioemilia, \"totale_casi\", \"Reggio\")\n",
    "    df_cases = concatandrename(df_cases, df_modena, \"totale_casi\", \"Modena\")\n",
    "    \n",
    "    df_deaths = concatandrename(df_deaths, df_ita, \"deceduti\", \"Italia\")\n",
    "    df_deaths = concatandrename(df_deaths, df_emiliaromagna, \"deceduti\", \"EmiliaRomagna\")\n",
    "    df_deaths = concatandrename(df_deaths, df_lombardia, \"deceduti\", \"Lombardia\")\n",
    "    df_deaths = concatandrename(df_deaths, df_veneto, \"deceduti\", \"Veneto\")\n",
    "    df_deaths = concatandrename(df_deaths, df_parma, \"deceduti\", \"Parma\")\n",
    "    df_deaths = concatandrename(df_deaths, df_reggioemilia, \"deceduti\", \"Reggio\")\n",
    "    df_deaths = concatandrename(df_deaths, df_modena, \"deceduti\", \"Modena\")\n",
    "    \n",
    "    df_recovered = concatandrename(df_recovered, df_ita, \"dimessi_guariti\", \"Italia\")\n",
    "    df_recovered = concatandrename(df_recovered, df_emiliaromagna, \"dimessi_guariti\", \"EmiliaRomagna\")\n",
    "    df_recovered = concatandrename(df_recovered, df_lombardia, \"dimessi_guariti\", \"Lombardia\")\n",
    "    df_recovered = concatandrename(df_recovered, df_veneto, \"dimessi_guariti\", \"Veneto\")\n",
    "    df_recovered = concatandrename(df_recovered, df_parma, \"dimessi_guariti\", \"Parma\")\n",
    "    df_recovered = concatandrename(df_recovered, df_reggioemilia, \"dimessi_guariti\", \"Reggio\")\n",
    "    df_recovered = concatandrename(df_recovered, df_modena, \"dimessi_guariti\", \"Modena\")\n",
    "    \n",
    "    # Prepara dati per processamento\n",
    "    x = np.asarray(list(df_cases['date_n']))\n",
    "    X = len(keys)*[x]\n",
    "    Y_cases = [np.asarray(list(df_cases[key])) for key in keys]\n",
    "    Y_deaths = [np.asarray(list(df_deaths[key])) for key in keys]\n",
    "    Y_recovered = [np.asarray(list(df_recovered[key])) for key in keys]\n",
    "    Label_cases = keys\n",
    "    Label_deaths = [Label_cases[i]+\"+\" for i in range(len(Label_cases))]\n",
    "    Label_recovered = [Label_cases[i]+\"|\" for i in range(len(Label_cases))]\n",
    "    \n",
    "    print(\"Elements in df_cases: {}\".format(len(df_cases)))\n",
    "    print(\"Elements in df_deaths: {}\".format(len(df_deaths)))\n",
    "    print(\"Elements in df_recovered: {}\".format(len(df_recovered)))\n",
    "    \n",
    "    return df_cases, df_deaths, df_recovered, X, Y_cases, Y_deaths, Y_recovered, Label_cases, Label_deaths, Label_recovered\n",
    "\n",
    "\n",
    "def country(df_cases, df_deaths, df_recovered, name):\n",
    "    df = pd.DataFrame(index=df_cases.index)\n",
    "    df = pd.concat([df, df_cases['date'], df_cases[name]], axis=1)\n",
    "    df = pd.concat([df, df_deaths[name]], axis=1)\n",
    "    df = pd.concat([df, df_recovered[name]], axis=1)\n",
    "    df.columns = ['date', 'confirmed', 'deaths', 'recovered']\n",
    "    df['confirmed_marker'] = 'Confirmed'\n",
    "    df['deaths_marker'] = 'Death'\n",
    "    df['recovered_marker'] = 'Recovered'\n",
    "    return df\n",
    "\n",
    "\n",
    "def daynumber2date(d):\n",
    "    return str(dt.datetime(2020, 1, 1) + dt.timedelta(days=int(d)))[:10]\n",
    "\n",
    "formatter_date = FuncFormatter(lambda x_val, tick_pos: \"{}\".format(daynumber2date(x_val)))\n",
    "formatter_log10 = FuncFormatter(lambda x_val, tick_pos: \"{}\".format(np.power(10,x_val)))\n",
    "\n",
    "\"\"\"\n",
    "Model\n",
    "\"\"\"\n",
    "def removenan(x, y):\n",
    "    keep = np.logical_not(np.logical_or(np.logical_or(np.isnan(x), np.isinf(x)), np.logical_or(np.isnan(y), np.isinf(y))))\n",
    "    x = list(compress(x, keep))\n",
    "    y = list(compress(y, keep))\n",
    "    if (sum(np.isnan(x)) + sum(np.isinf(x)) + sum(np.isnan(y) + sum(np.isinf(y)))) > 0:\n",
    "        print(\"Stammerda non funziona\")\n",
    "    return x, y\n",
    "\n",
    "def logistic1_model(x, a, dtau, tau):\n",
    "    return a/(1+np.exp(-(x-dtau)/tau))\n",
    "\n",
    "def logistic2_model(x, a, b, dtau, tau):\n",
    "    return a/(1+b*np.exp(-np.power((x-dtau)/tau, 1.0)))\n",
    "\n",
    "def logistic21_model(x, a, b, dtau, tau, ni):\n",
    "    return a/np.power(1+b*np.exp(-np.power((x-dtau)/tau, 1.0)), 1.0/ni)\n",
    "\n",
    "def logistic3_model(x, a, b, tau, alpha):\n",
    "    # usato da Matteo P.\n",
    "    return a/(1+b*np.exp(-np.power(x/tau, alpha)))\n",
    "\n",
    "def logistic31_model(x, a, b, tau, alpha, ni):\n",
    "    return a/np.power(1+b*np.exp(-np.power(x/tau, alpha)), 1.0/ni)\n",
    "\n",
    "def logistic32_model(x, a, b, tau, alpha, ni, k):\n",
    "    return k + (a-k)/np.power(1+b*np.exp(-np.power(x/tau, alpha)), 1.0/ni)\n",
    "\n",
    "def linear_model(x, a, b):\n",
    "    return a*x+b\n",
    "\n",
    "def quadratic_model(x, a, b, c):\n",
    "    return a*(x**2)+b*x+c\n",
    "\n",
    "def model(model, x, y, horizon=0, threshold=10, relative_rmse = False, verbose=False):\n",
    "    #x = np.asarray(x)\n",
    "    #y = np.asarray(y)\n",
    "    \n",
    "    if len(x) > 0:\n",
    "    \n",
    "        if horizon == 0:\n",
    "            x_pred = x\n",
    "        else:\n",
    "            x_pred = np.arange(min(x), max(x)+horizon, 1)\n",
    "        \n",
    "        if model == \"logistic1\":\n",
    "            try:\n",
    "                p0 = [20000, 100, 2]\n",
    "                fit = curve_fit(logistic1_model, x, y, p0=p0)\n",
    "                \n",
    "                y_pred = logistic1_model(x_pred, fit[0][0], fit[0][1], fit[0][2])\n",
    "    \n",
    "                # End date\n",
    "                sol = int(fsolve(lambda x : logistic1_model(x,fit[0][0],fit[0][1],fit[0][2]) - int(fit[0][2]),fit[0][1]))\n",
    "                end_date = dt.datetime(2020, 1, 1) + dt.timedelta(days=sol)\n",
    "                #print \"End date: \" + str(end_date)\n",
    "                \n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "                print(model)\n",
    "                x_pred = [0]\n",
    "                y_pred = [0]\n",
    "                fit = [[1, 0, 0], [0]]\n",
    "                end_date = 0\n",
    "        \n",
    "        if model == \"logistic2\":\n",
    "            try:\n",
    "                p0 = [1.52646450e+05, 1.56215676e-01, 9.59401246e+01, 6.23161909e+00]\n",
    "                fit = curve_fit(logistic2_model, x, y, maxfev=100000, p0=p0)\n",
    "                \n",
    "                y_pred = logistic2_model(x_pred, fit[0][0], fit[0][1], fit[0][2], fit[0][3])\n",
    "                \n",
    "            except Exception:\n",
    "                traceback.print_exc()\n",
    "                print(model)\n",
    "                x_pred = [0]\n",
    "                y_pred = [0]\n",
    "                fit = [[0, 0, 1], [0]]\n",
    "            \n",
    "            end_date = 0\n",
    "            \n",
    "        if model == \"logistic21\":\n",
    "            try:                \n",
    "                #p0 = [1.52646450e+05, 1.56215676e-01, 9.59401246e+01, 6.23161909e+00, 1.0]\n",
    "                # Uso il valore massimo dei casi come a0, questo fa si' che il modello converga per tutti i set, se no non convergerebbe\n",
    "                p0 = [max(y), 1.56215676e-01, 9.59401246e+01, 6.23161909e+00, 1.0]\n",
    "                bounds = ([-np.inf, -np.inf, -np.inf, -np.inf, 0.000000],\n",
    "                          [ np.inf,  np.inf,  np.inf,  np.inf, 8.000000])\n",
    "                fit = curve_fit(logistic21_model, x, y, maxfev=100000, p0=p0)\n",
    "                \n",
    "                y_pred = logistic21_model(x_pred, fit[0][0], fit[0][1], fit[0][2], fit[0][3], fit[0][4])\n",
    "                \n",
    "            except Exception:\n",
    "                traceback.print_exc()\n",
    "                print(model)\n",
    "                x_pred = [0]\n",
    "                y_pred = [0]\n",
    "                fit = [[0, 0, 1], [0]]\n",
    "            \n",
    "            end_date = 0\n",
    "            \n",
    "        if model == \"logistic3\":\n",
    "            try:\n",
    "                p0 = [1.52646560e+05, 1.56040732e-01, 9.59471514e+01, 1.5]\n",
    "                bounds = ([-np.inf, -np.inf, -np.inf, 0.0000009],\n",
    "                          [ np.inf,  np.inf,  np.inf, 8.0000000])\n",
    "                fit = curve_fit(logistic3_model, x, y, maxfev=100000, bounds=bounds, p0=p0)\n",
    "                \n",
    "                y_pred = logistic3_model(x_pred, fit[0][0], fit[0][1], fit[0][2], fit[0][3])\n",
    "                \n",
    "            except Exception:\n",
    "                traceback.print_exc()\n",
    "                print(model)\n",
    "                x_pred = [0]\n",
    "                y_pred = [0]\n",
    "                fit = [[0, 0, 1], [0]]\n",
    "            \n",
    "            end_date = 0\n",
    "            \n",
    "        if model == \"logistic31\":\n",
    "            try:\n",
    "                p0 = [1.52646560e+05, 1.56040732e-01, 9.59471514e+01, 1.5, 1.0]\n",
    "                bounds = ([-np.inf, -np.inf, -np.inf, 0.0000009, 0.000000],\n",
    "                          [ np.inf,  np.inf,  np.inf, 8.0000000, 8.000000])\n",
    "                fit = curve_fit(logistic31_model, x, y, maxfev=100000, bounds=bounds, p0=p0)\n",
    "                \n",
    "                y_pred = logistic31_model(x_pred, fit[0][0], fit[0][1], fit[0][2], fit[0][3], fit[0][4])\n",
    "                \n",
    "            except Exception:\n",
    "                traceback.print_exc()\n",
    "                print(model)\n",
    "                x_pred = [0]\n",
    "                y_pred = [0]\n",
    "                fit = [[0, 0, 1], [0]]\n",
    "            \n",
    "            end_date = 0\n",
    "            \n",
    "        if model == \"logistic32\":\n",
    "            try:\n",
    "                p0 = [1.52646560e+05, 1.56040732e-01, 9.59471514e+01, 1.5, 1.0, 0.0]\n",
    "                bounds = ([-np.inf, -np.inf, -np.inf, 0.000009, 0.000000, -np.inf],\n",
    "                          [ np.inf,  np.inf,  np.inf, 8.000000, 8.000000,  np.inf])\n",
    "                fit = curve_fit(logistic32_model, x, y, maxfev=100000, bounds=bounds, p0=p0)\n",
    "                \n",
    "                y_pred = logistic32_model(x_pred, fit[0][0], fit[0][1], fit[0][2], fit[0][3], fit[0][4], fit[0][5])\n",
    "                \n",
    "            except Exception:\n",
    "                traceback.print_exc()\n",
    "                print(model)\n",
    "                x_pred = [0]\n",
    "                y_pred = [0]\n",
    "                fit = [[0, 0, 1], [0]]\n",
    "            \n",
    "            end_date = 0\n",
    "        \n",
    "        elif model == \"linear\":\n",
    "            try:\n",
    "                x_pred = np.arange(min(x), max(x)+horizon, 1)\n",
    "                fit = curve_fit(linear_model, x, y)\n",
    "                y_pred = linear_model(x_pred, fit[0][0], fit[0][1])\n",
    "            except:\n",
    "                x_pred = [0]\n",
    "                y_pred = [0]\n",
    "                fit = [[0, 0], [0]]\n",
    "                \n",
    "            end_date = 0\n",
    "                \n",
    "        elif model == \"quadratic\":\n",
    "            try:\n",
    "                x_pred = np.arange(min(x), max(x)+horizon, 1)\n",
    "                fit = curve_fit(quadratic_model, x, y)\n",
    "                y_pred = quadratic_model(x_pred, fit[0][0], fit[0][1], fit[0][2])\n",
    "            except:\n",
    "                x_pred = [0]\n",
    "                y_pred = [0]\n",
    "                fit = [[0, 0, 0], [0]]\n",
    "                \n",
    "            end_date = 0\n",
    "        \n",
    "        # Calcolo RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(y, y_pred[:len(y)]))\n",
    "        if relative_rmse:\n",
    "            rmse = rmse / max(y)\n",
    "        \n",
    "        # Cerco quando la derivata e' al di sotto di una certa soglia, quindi nuovi casi inferiori a ...\n",
    "        d = np.diff(y_pred)\n",
    "        zero_crossings = np.where(np.diff(np.sign(d-threshold)))[0]\n",
    "        if len(zero_crossings)>0:\n",
    "            last_zero_crossing_day = x_pred[zero_crossings[-1]]\n",
    "            end_date = last_zero_crossing_day\n",
    "        else:\n",
    "            end_date = -1\n",
    "            \n",
    "        if verbose:\n",
    "            #print len(x)\n",
    "            #print len(y)\n",
    "            #print len(x_pred)\n",
    "            #print len(y_pred)\n",
    "            print(fit[0])\n",
    "        \n",
    "        return x_pred, y_pred, fit, rmse, end_date\n",
    "    \n",
    "    else:\n",
    "        return [], [], [], 0, 0\n",
    "\n",
    "\n",
    "def run_time_model(X, Y, past=0, horizon=0, threshold=10, relative_rmse=False, verbose=False):\n",
    "    Fit = list()\n",
    "    X_pred = list()\n",
    "    Y_pred = list()\n",
    "    Rmse = list()\n",
    "    End_date = list()\n",
    "    \n",
    "    if past>0:\n",
    "        print(\"Non hai capito un cazzo, past deve essere < 0\")\n",
    "    \n",
    "    for i, (x, y) in enumerate(zip(X,Y)):\n",
    "        x, y = removenan(x, y)\n",
    "        x = x[:len(x)+past]\n",
    "        y = y[:len(y)+past]\n",
    "        \n",
    "        #x_pred, y_pred, fit, end_date = model(\"logistic1\", x, y, horizon)\n",
    "        x_pred, y_pred, fit, rmse, end_date = model(\"logistic21\", x, y, horizon=horizon, threshold=threshold, relative_rmse=relative_rmse, verbose=verbose)\n",
    "        #x_pred, y_pred, fit, end_date = model(\"logistic3\", x, y, horizon)\n",
    "        #x_pred, y_pred, fit, end_date = model(\"logistic31\", x, y, horizon, verbose=True)\n",
    "        #x_pred, y_pred, fit, end_date = model(\"logistic32\", x, y, horizon, verbose=True)\n",
    "        \n",
    "        Fit.append(fit)\n",
    "        X_pred.append(x_pred)\n",
    "        Y_pred.append(y_pred)\n",
    "        Rmse.append(rmse)\n",
    "        End_date.append(end_date)\n",
    "        \n",
    "    return X_pred, Y_pred, Fit, Rmse, End_date\n",
    "\n",
    "\n",
    "def run_time_model_timemachine(X, Y, Label, threshold):\n",
    "    timemachine = range(-20,0+1,1)\n",
    "    Timemachine_rmse = list()\n",
    "    Timemachine_enddate = list()\n",
    "        \n",
    "    for past in timemachine:\n",
    "        X_pred_cases, Y_pred_cases, Fit_cases, Rmse_cases, End_date_cases = run_time_model(X, Y, past=past, horizon=90, threshold=threshold, relative_rmse=True, verbose=False)\n",
    "        Timemachine_rmse.append(Rmse_cases)\n",
    "        Timemachine_enddate.append(End_date_cases)\n",
    "            \n",
    "    # Riordina risultati nel formato solito (per paese)\n",
    "    paese = 0\n",
    "    lista_enddate = list()\n",
    "    lista_rmse = list()\n",
    "    for paese in range(0, len(X)):\n",
    "        lista_enddate_paese = list()\n",
    "        lista_rmse_paese = list()\n",
    "        for giorno in range(0, len(Timemachine_enddate)):\n",
    "            lista_enddate_paese.append(Timemachine_enddate[giorno][paese])\n",
    "            lista_rmse_paese.append(Timemachine_rmse[giorno][paese])\n",
    "        lista_enddate.append(lista_enddate_paese)\n",
    "        lista_rmse.append(lista_rmse_paese)\n",
    "    \n",
    "    # Grafico\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    ax1.yaxis.set_major_formatter(formatter_date)\n",
    "    \n",
    "    for i in range(len(lista_enddate)):\n",
    "        ax1.plot(timemachine, lista_enddate[i], label=Label[i])\n",
    "    ax1.legend()\n",
    "    ax1.set_title(\"Fine prevista\")\n",
    "    ax1.xaxis.set_label_text(\"Giorno nel passato\")\n",
    "    ax1.yaxis.set_label_text(\"Giorno\")\n",
    "    ax1.yaxis.grid(True, which='major')\n",
    "    ax1.yaxis.grid(True, which='minor')\n",
    "    \n",
    "    ax2 = fig.add_subplot(212)\n",
    "    for i in range(len(lista_enddate)):\n",
    "        ax2.plot(timemachine, lista_rmse[i], label=Label[i])\n",
    "    ax2.set_title(\"RMSE\")\n",
    "    ax2.xaxis.set_label_text(\"Giorno nel passato\")\n",
    "    ax2.yaxis.set_label_text(\"RMSE\")\n",
    "    ax2.yaxis.grid(True, which='major')\n",
    "    ax2.yaxis.grid(True, which='minor')\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def run_cross_model(Y1,Y2):\n",
    "    Fit = list()\n",
    "    Y1_pred = list()\n",
    "    Y2_pred = list()\n",
    "    \n",
    "    for i, (y1, y2) in enumerate(zip(Y1, Y2)):\n",
    "        y1, y2 = removenan(y1, y2)\n",
    "        y1_pred, y2_pred, fit = model(\"linear\", y1, y2)\n",
    "        Fit.append(fit)\n",
    "        Y1_pred.append(y1_pred)\n",
    "        Y2_pred.append(y2_pred)\n",
    "        \n",
    "    return Y1_pred, Y2_pred, Fit\n",
    "\n",
    "\n",
    "def plot_timeseries(title, logplot, threshold, \\\n",
    "                    X, Y, X_pred, Y_pred, Label):\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#1f77b4', '#ff7f0e']\n",
    "    plt.rcParams['figure.figsize'] = [20, 10]\n",
    "    plt.rc('font', size=14)\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ax1 = fig.add_subplot(221)\n",
    "    for idx, (x, y, x_pred, y_pred, label) in enumerate(zip(X, Y, X_pred, Y_pred, Label)):\n",
    "        if logplot:\n",
    "            ax1.scatter(x, np.log10(y), marker='.', color=colors[idx], label=label)\n",
    "            ax1.plot(x_pred, np.log10(y_pred), color=colors[idx], label=label)\n",
    "        else:\n",
    "            ax1.scatter(x, y, marker='.', color=colors[idx], label=label)\n",
    "            ax1.plot(x_pred, y_pred, color=colors[idx], label=label)\n",
    "    \n",
    "    ax1.set_title(title)\n",
    "    ax1.xaxis.set_label_text(\"Giorno\")\n",
    "    ax1.yaxis.set_label_text(\"Casi\")\n",
    "    ax1.legend()\n",
    "    ax1.xaxis.set_major_formatter(formatter_date)\n",
    "    if logplot:\n",
    "        ax1.set_ylim(0, 6)\n",
    "        ax1.yaxis.set_major_formatter(formatter_log10)\n",
    "    else:\n",
    "        ax1.set_ylim(0, 1000000)\n",
    "    ax1.yaxis.grid(True, which='major')\n",
    "    ax1.yaxis.grid(True, which='minor')\n",
    "    \n",
    "    # Nuovi casi previsti (derivata della previsione comulativa)\n",
    "    ax2 = fig.add_subplot(222)\n",
    "    ax2.set_title(title + \" (derivata)\")\n",
    "    for idx, (x, y, x_pred, y_pred, label) in enumerate(zip(X, Y, X_pred, Y_pred, Label)):\n",
    "        d = np.diff(y_pred)\n",
    "        ax2.plot(x_pred[1:], np.log10(d), color=colors[idx], label=label)\n",
    "        \n",
    "    ax2.xaxis.set_label_text(\"Giorno\")\n",
    "    ax2.yaxis.set_label_text(\"Nuovi casi\")\n",
    "    ax2.set_ylim(0, 5)\n",
    "    ax2.xaxis.set_major_formatter(formatter_date)\n",
    "    ax2.yaxis.set_major_formatter(formatter_log10)\n",
    "    ax2.set_yticks([np.log10(threshold)], minor=True)\n",
    "    ax2.xaxis.grid(True, which='major')\n",
    "    ax2.xaxis.grid(True, which='minor')\n",
    "    ax2.yaxis.grid(True, which='major')\n",
    "    ax2.yaxis.grid(True, which='minor')\n",
    "    \n",
    "    # Errori\n",
    "    ax3 = fig.add_subplot(223)\n",
    "    ax3.set_title(title + \" (errori)\")\n",
    "    for idx, (x, y, x_pred, y_pred, label) in enumerate(zip(X, Y, X_pred, Y_pred, Label)):\n",
    "        x, y = removenan(x, y)\n",
    "        ax3.plot(x, y_pred[:len(y)]-y, color=colors[idx], label=label)\n",
    "        \n",
    "    ax3.set_ylim(-3000, 3000)\n",
    "    ax3.yaxis.grid(True, which='major')\n",
    "    ax3.yaxis.grid(True, which='minor')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_timeseries2(title, logplot, threshold, \\\n",
    "                     X1, Y1, X1_pred, Y1_pred, Label1, \\\n",
    "                     X2, Y2, X2_pred, Y2_pred, Label2, scale2=1.0):\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#1f77b4', '#ff7f0e']\n",
    "    plt.rcParams['figure.figsize'] = [20, 10]\n",
    "    plt.rc('font', size=14)\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ax1 = fig.add_subplot(111)\n",
    "    for idx, (x1, y1, x1_pred, y1_pred, label1, x2, y2, x2_pred, y2_pred, label2) in enumerate(zip(X1, Y1, X1_pred, Y1_pred, Label1, X2, Y2, X2_pred, Y2_pred, Label2)):\n",
    "        if logplot:\n",
    "            ax1.scatter(x1, np.log10(y1), marker='.', color=colors[idx], label=label1)\n",
    "            ax1.plot(x1_pred, np.log10(y1_pred), color=colors[idx], label=label1)\n",
    "            ax1.scatter(x2, np.log10(y2*scale2), marker='+', color=colors[idx], label=label2)\n",
    "            ax1.plot(x2_pred, np.log10(y2_pred*scale2), color=colors[idx], label=label2)\n",
    "        else:\n",
    "            ax1.scatter(x1, y1, marker='.', color=colors[idx], label=label1)\n",
    "            ax1.plot(x1_pred, y1_pred, color=colors[idx], label=label1)\n",
    "            ax1.scatter(x2, y2*scale2, marker='+', color=colors[idx], label=label2)\n",
    "            ax1.plot(x2_pred, y2_pred*scale2, color=colors[idx], label=label2)\n",
    "    \n",
    "    ax1.set_title(title)\n",
    "    ax1.xaxis.set_label_text(\"Giorno\")\n",
    "    ax1.yaxis.set_label_text(\"Casi\")\n",
    "    ax1.legend()\n",
    "    #ax1.xaxis.set_major_formatter(formatter_date)\n",
    "    if logplot:\n",
    "        ax1.set_ylim(0, 6)\n",
    "        ax1.yaxis.set_major_formatter(formatter_log10)\n",
    "    else:\n",
    "        ax1.set_ylim(0, 200000)\n",
    "    ax1.yaxis.grid(True, which='major')\n",
    "    ax1.yaxis.grid(True, which='minor')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def plot_crossseries(title, xlabel, ylabel,\n",
    "                     Y1, Y2, Label, Y1_pred=[], Y2_pred=[], Fit=[]):\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#1f77b4', '#ff7f0e']\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.rcParams['figure.figsize'] = [20, 10]\n",
    "    plt.rc('font', size=14)\n",
    "    \n",
    "    if len(Y1_pred) > 0:\n",
    "        fit_active = True\n",
    "    else:\n",
    "        fit_active = False\n",
    "    \n",
    "    for idx, (y1, y2, label) in enumerate(zip(Y1, Y2, Label)):\n",
    "        #ax.scatter(y1, y2, marker='.', color=colors[idx], label=label)\n",
    "        ax.plot(y1, y2, marker='.', color=colors[idx], label=label)\n",
    "        \n",
    "        if fit_active:\n",
    "            y1_pred = Y1_pred[idx]\n",
    "            y2_pred = Y2_pred[idx]\n",
    "            fit = Fit[idx]\n",
    "            ax.plot(y1_pred, y2_pred, color=colors[idx], label=label)\n",
    "            #print(\"%s : % 5.2f %% deaths/total cases\" %(label, fit[0][0]*100))  \n",
    "              \n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_label_text(xlabel)\n",
    "    ax.yaxis.set_label_text(ylabel)\n",
    "    ax.xaxis.grid(True, which='major')\n",
    "    ax.xaxis.grid(True, which='minor')\n",
    "    ax.yaxis.grid(True, which='major')\n",
    "    ax.yaxis.grid(True, which='minor')\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Copiati da https://www.kaggle.com/volpatto/covid-19-study-with-epidemiology-models\n",
    "\"\"\"\n",
    "def altair_plot_for_confirmed_and_deaths(df_grouped: pd.DataFrame, data_at_x_axis: str='date') -> alt.Chart:\n",
    "    confirmed_plot = alt.Chart(df_grouped).mark_circle(size=60).encode(\n",
    "        x=alt.X(data_at_x_axis, axis=alt.Axis(title='Date')),\n",
    "        y=alt.Y('confirmed', axis=alt.Axis(title='Cases'), title='Confirmed'),\n",
    "        color=alt.Color(\"confirmed_marker\", title=\"Cases\"),\n",
    "    )\n",
    "\n",
    "    deaths_plot = alt.Chart(df_grouped).mark_circle(size=60).encode(\n",
    "        x=data_at_x_axis,\n",
    "        y='deaths',\n",
    "        color=alt.Color(\"deaths_marker\"),\n",
    "    )\n",
    "\n",
    "    return confirmed_plot + deaths_plot\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Main\n",
    "\"\"\"\n",
    "def main():\n",
    "    plt.close('all')\n",
    "    \n",
    "    # Caricamento dati\n",
    "    \n",
    "    if 0:\n",
    "        keys = ['Italia',\\\n",
    "                'Spain', \\\n",
    "                'Germany', \\\n",
    "                'France', \\\n",
    "                'US', \\\n",
    "                'China'\n",
    "                ]\n",
    "    if 0:\n",
    "        keys = ['Italia',\\\n",
    "                'EmiliaRomagna', \\\n",
    "                'Lombardia', \\\n",
    "                'Veneto', \\\n",
    "                #'Parma', \\\n",
    "                #'Modena', \\\n",
    "                ]\n",
    "    if 1:\n",
    "         keys = ['Italia']\n",
    "         \n",
    "         \n",
    "    # Caricamento dati\n",
    "    df_cases, df_deaths, df_recovered, X, Y_cases, Y_deaths, Y_recovered, Label_cases, Label_deaths, Label_recovered =  load(keys)\n",
    "    prova = country(df_cases, df_deaths, df_recovered, \"Italy\")\n",
    "    print(df_cases)\n",
    "    altair_plot_for_confirmed_and_deaths(prova).interactive()\n",
    "    \n",
    "    \n",
    "    #print(prova)\n",
    "    #plt.plot(prova.index, prova['confirmed'])\n",
    "    \n",
    "    \n",
    "    # Previsione casi\n",
    "    days_ago = 0\n",
    "    threshold = 50\n",
    "    X_pred_cases, Y_pred_cases, Fit_cases, Rmse_cases, End_date_cases = run_time_model(X, Y_cases, past=days_ago, horizon=90, threshold=threshold)\n",
    "    X_pred_deaths, Y_pred_deaths, Fit_deaths, Rmse_deaths, End_date_deaths = run_time_model(X, Y_deaths, past=days_ago, horizon=90, threshold=threshold)\n",
    "    \n",
    "    if 0:\n",
    "        plot_timeseries(\"Casi\", True, threshold,\\\n",
    "                        X, Y_cases, X_pred_cases, Y_pred_cases, Label_cases)\n",
    "    \n",
    "        print(\"Predicted end dates:\")\n",
    "        for i, date in enumerate(End_date_cases):\n",
    "            print(\"{}\\t\\t(as of {},\\t rmse={}):\\t{}\".format(Label_cases[i], daynumber2date(max(X[i])-days_ago), Rmse_cases[i], daynumber2date(date)))\n",
    "    \n",
    "    \n",
    "    # Previsione morti\n",
    "    if 0:\n",
    "        plot_timeseries(\"Morti\", True, threshold,\\\n",
    "                        X, Y_deaths, X_pred_deaths, Y_pred_deaths, Label_deaths)\n",
    "        \n",
    "        print(\"Predicted end dates (deaths):\")\n",
    "        for i, date in enumerate(End_date_deaths):\n",
    "            print(\"{}\\t\\t(as of {},\\t rmse={}):\\t{}\".format(Label_deaths[i], daynumber2date(max(X[i])-days_ago), Rmse_deaths[i], daynumber2date(date)))\n",
    "            \n",
    "    \n",
    "    if 0:\n",
    "        plot_timeseries2(\"Casi\", True, threshold,\\\n",
    "                         X, Y_cases, X_pred_cases, Y_pred_cases, Label_cases,\\\n",
    "                         X, Y_deaths, X_pred_deaths, Y_pred_deaths, Label_deaths, scale2=7.7)\n",
    "    \n",
    "    \n",
    "    # Come varia la previsione nel tempo\n",
    "    if 0:\n",
    "        run_time_model_timemachine(X, Y_cases, Label_cases, threshold=10)\n",
    "    \n",
    "    \n",
    "    # Dati attuali\n",
    "    N = 5\n",
    "    b = N*[1.0/N]\n",
    "    \n",
    "    if 0:\n",
    "        plot_crossseries(\"Crescita contagi vs contagi totali\", \"Cases\", \"New cases\", \\\n",
    "                         np.log10([Y_cases[i][1:] for i in range(len(Y_cases))]), \\\n",
    "                         np.log10(lfilter(b, [1.], np.diff(Y_cases))), \\\n",
    "                         Label_cases)\n",
    "    \n",
    "    if 0:\n",
    "        plot_crossseries(\"Crescita morti vs morti totali\", \"Cases\", \"New cases\", \\\n",
    "                         np.log10([Y_deaths[i][1:] for i in range(len(Y_deaths))]), \\\n",
    "                         np.log10(lfilter(b, [1.], np.diff(Y_deaths))), \\\n",
    "                         Label_deaths)\n",
    "    \n",
    "    if 0:\n",
    "        plot_crossseries(\"Morti vs casi totali\", \"Cases\", \"New cases\", \\\n",
    "                         np.log10(Y_cases), \\\n",
    "                         np.log10(lfilter(b, [1.], Y_deaths)), \\\n",
    "                         Label_deaths)\n",
    "    \n",
    "    if 0:\n",
    "        plot_crossseries(\"Crescita morti vs casi totali\", \"Cases\", \"New cases\", \\\n",
    "                         np.log10([Y_cases[i][1:] for i in range(len(Y_cases))]), \\\n",
    "                         np.log10(lfilter(b, [1.], np.diff(Y_deaths))), \\\n",
    "                         Label_deaths)\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      date  confirmed   deaths  recovered  \\\n",
      "date_n                                                                      \n",
      "21      <map object at 0x0000015AABBD5F48>        0.0      0.0        0.0   \n",
      "22      <map object at 0x0000015AABBD5F48>        0.0      0.0        0.0   \n",
      "23      <map object at 0x0000015AABBD5F48>        0.0      0.0        0.0   \n",
      "24      <map object at 0x0000015AABBD5F48>        0.0      0.0        0.0   \n",
      "25      <map object at 0x0000015AABBD5F48>        0.0      0.0        0.0   \n",
      "...                                    ...        ...      ...        ...   \n",
      "103     <map object at 0x0000015AABBD5F48>   159516.0  20465.0    35435.0   \n",
      "104     <map object at 0x0000015AABBD5F48>   162488.0  21067.0    37130.0   \n",
      "105     <map object at 0x0000015AABBD5F48>   165155.0  21645.0    38092.0   \n",
      "106     <map object at 0x0000015AABBD5F48>   168941.0  22170.0    40164.0   \n",
      "107     <map object at 0x0000015AABBD5F48>   172434.0  22745.0    42727.0   \n",
      "\n",
      "       confirmed_marker deaths_marker recovered_marker  \n",
      "date_n                                                  \n",
      "21            Confirmed         Death        Recovered  \n",
      "22            Confirmed         Death        Recovered  \n",
      "23            Confirmed         Death        Recovered  \n",
      "24            Confirmed         Death        Recovered  \n",
      "25            Confirmed         Death        Recovered  \n",
      "...                 ...           ...              ...  \n",
      "103           Confirmed         Death        Recovered  \n",
      "104           Confirmed         Death        Recovered  \n",
      "105           Confirmed         Death        Recovered  \n",
      "106           Confirmed         Death        Recovered  \n",
      "107           Confirmed         Death        Recovered  \n",
      "\n",
      "[87 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(prova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
